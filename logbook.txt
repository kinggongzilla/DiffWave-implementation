Practical work stuff I tried:

1. Learn one single 5 second sine wave:
Result: After 10k steps, inference was still noisy but one could clearly hear the sine wave

2. Train on 7k samples for 20 Epochs
Result: Only noise when sampling. Loss constant after 10 epochs

3. Train on one single 5 second sample
loss constant after first 1000 steps

4. Train on sine wave for 15k steps
works reasonably well. Loss stays roughly the same for last 3.5k steps.
Audio is still noisy but one can clearly hear the sine wave.

5. Train on whole 150k samples for one epoch
Loss stopped going down after first 10k steps (out of 20k). Produces only noise with some rythmic sound artefacts

6. Reduced sample rate to 8k. Now able to load model with 1.6M parameters and batch size 8, with 4 second samples into memory. 
Paper uses ~24M params for unconditional model?? I will train on 900 samples (=1h of audio) for 500 epochs. In paper they trained for 1M steps!!




16.4.2021
fixed variance schedule from np.linspace(10e-4,0.02) to np.linspace(1e-4,0.02)

20.4.2023
THE ISSUE WAS THAT WHEN A NEW PYTORCH LIGHTNING RUN IS STARTED THE NEW MODEL IS NOT SAVED AS OUTPUT/MODELS/BEST_MODEL.PT BUT AS OUTPUT/MODELS/BEST_MODEL-V1.PT, IF BEST_MODEL.PT ALREADY EXISTS!!!



2.6.2023
Model trained on 5 different sine waves with 5 different frequencies always produces the same sine wave when sampling.
I looked at the magnitude of x (noise input) and the magnitude of the conditioning variable after the SpectrogramConditioner and conditioning_var is significantly smaller.
Magnitude of conditioning var is always the same, regardless of what sine wave spectrogram i use as input.

Magnitude of conditioning_var:  tensor(0.0339, device='cuda:0')
Magnitude of x:  tensor(0.4453, device='cuda:0')


3.6.2023
Tried experiment from 2.6. with original diffwave model. When trained on 5 different sine wave frequencies, the model also outputs exactly the same sine wave, regardless of which spectrogram is used as input.
