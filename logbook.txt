Practical work stuff I tried:

1. Learn one single 5 second sine wave:
Result: After 10k steps, inference was still noisy but one could clearly hear the sine wave

2. Train on 7k samples for 20 Epochs
Result: Only noise when sampling. Loss constant after 10 epochs

3. Train on one single 5 second sample
loss constant after first 1000 steps

4. Train on sine wave for 15k steps
works reasonably well. Loss stays roughly the same for last 3.5k steps.
Audio is still noisy but one can clearly hear the sine wave.

5. Train on whole 150k samples for one epoch
Loss stopped going down after first 10k steps (out of 20k). Produces only noise with some rythmic sound artefacts

6. Train on 4 second samples at 8Khz sample rate and generate 4 second samples to make it easier for the network to learn. 
I chunked the raw_data into 4 second audio snippets. In the paper they trained on 8.7h of audio for unconditional generation. 
Since I am using a lower sample rate and shorter samples, I can make the model bigger without running into memory issues.
