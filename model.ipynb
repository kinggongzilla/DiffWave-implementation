{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c0d3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hause\\miniconda3\\envs\\practical_work\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "import soundfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('./source/'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from model import DiffWave, DiffWaveBlock\n",
    "from dataset import ChunkedMusDBHQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f986c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_data = ChunkedMusDBHQ(audio_dir='data/chunked_audio/')\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    chunked_data,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "942d4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test forward pass with one sample\n",
    "sample = next(iter(trainloader)) #waveform, sample_rate\n",
    "waveform = sample[0]\n",
    "waveform.shape #batch size, num channels, sample length\n",
    "\n",
    "#only take first channel of sample; indexing is done with 0:1 instead of [0], otherwise shape is not kept the same\n",
    "waveform = waveform[:,0:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93d93e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DiffWave(32)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23662c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.forward(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07554ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 220500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practical_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b3bd52304cf4f8503640a78f39433e8f3f957e5a2223726550e53c8c8975ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
