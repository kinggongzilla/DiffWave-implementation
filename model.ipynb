{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c0d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a7b0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2],[1, 4], [1,1]])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffWaveBlock(torch.nn.Module):\n",
    "    def __init__(self, layer_index, C) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_index = layer_index\n",
    "        self.C = C\n",
    "        self.input = None\n",
    "        self.x_skip = None\n",
    "\n",
    "        # diffusion time step embedding\n",
    "        self.fc_timestep = torch.nn.Linear(512, C)\n",
    "\n",
    "        #bi directional conv\n",
    "        self.conv_dilated = torch.nn.Conv1d(C, 2*C, 3, dilation=2**layer_index, padding='same')\n",
    "\n",
    "        self.conv_skip = torch.nn.Conv1d(C, C, 1)\n",
    "        self.conv_next = torch.nn.Conv1d(C, C, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "\n",
    "        self.input = x #TODO: check if passing forward through layers happens inplace!. Potentially use self.input = x.clone()\n",
    "        t = self.fc_timestep(t)\n",
    "        x = x + t #broadcast addition\n",
    "        x = self.conv_dilated(x)\n",
    "        x_tanh, x_sigmoid = x.chunk(2, dim=1)\n",
    "        x_tanh = torch.tanh(x_tanh)\n",
    "        x_sigmoid = torch.sigmoid(x_sigmoid)\n",
    "        x = x_tanh * x_sigmoid\n",
    "        self.x_skip = self.conv_skip(x)\n",
    "        x = self.conv_next(x) + self.input\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c74e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffWave(torch.nn.Module):\n",
    "    def __init__(self, C) -> None:\n",
    "        super().__init__()\n",
    "        #in\n",
    "        self.fc1 = torch.nn.Linear(128, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 512)\n",
    "        self.conv_in_1 = torch.nn.Conv1d(1, C, 1)\n",
    "\n",
    "        #blocks\n",
    "        self.layer1 = DiffWaveBlock(0, C)\n",
    "        self.layer2 = DiffWaveBlock(1, C)\n",
    "\n",
    "        #out\n",
    "        self.conv_out_1 = torch.nn.Conv1d(C, C, 1)\n",
    "        self.conv_out_2 = torch.nn.Conv1d(C, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "\n",
    "        #waveform input\n",
    "        x = self.conv_in_1(x)\n",
    "\n",
    "        #time embedding t=0\n",
    "        t=0\n",
    "        t = self.fc1(t)\n",
    "        t = F.silu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = F.silu(t)\n",
    "        x = self.layer1(x, t)\n",
    "\n",
    "        #time embedding t=1\n",
    "        t=1\n",
    "        t = self.fc1(t)\n",
    "        t = F.silu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = F.silu(t)\n",
    "        x = self.layer2(x, t)\n",
    "\n",
    "        #out\n",
    "        x = self.conv_out_1(x)\n",
    "        x = self.conv_out_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1e0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d06b7f189755ffe906b3c03a1b4897b441226e30fd3256924a77eb54768b435"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
